# -*- coding: utf-8 -*-
"""PyTorch_basics.ipynb의 사본

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1622iNzDcpO5DdcQETH2jJJVDo7zYeUBI
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/기록_포스토용/깃헙/파이토치 튜토리얼

import torch 
import torchvision
import torch.nn as nn
import numpy as np 
import torchvision.transforms as transforms

# ================================================================== #
#                     1. Basic autograd example 1                    #
# ================================================================== #

# Create tensors
x = torch.tensor(1., requires_grad=True) # requires_grad=True -> 연산기록 수행
w = torch.tensor(2., requires_grad=True)
b = torch.tensor(3., requires_grad=True)

# Build a computational graph
y = w* x + b

# compute gradients
y.backward()

print(x.grad) # tensor(2.)
print(w.grad) # tensor(1.)
print(b.grad) # tensor(1.)

# ================================================================== #
#                    2. Basic autograd example 2                     #
# ================================================================== #

# Create tensors of shape (10, 3) and (10, 2)
x = torch.randn(10, 3)
y = torch.randn(10, 2)

# Build a fully connected later
linear = nn.Linear(3,2)
print("w: ", linear.weight)
print("b: ", linear.bias)

# Build loss function and optimizer
criterion = nn.MSELoss()
optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)

# forward pass
pred = linear(x)

# compute loss
loss = criterion(pred, y)
print("loss: ", loss.item())

# backward pass
loss.backward()

# print out the gradients
print("dL/dW ", linear.weight.grad)
print("dL/db ", linear.bias.grad)

# 1-step gradient descent
optimizer.step()

# print out the loss after 1-step gradient descent
pred = linear(x)
loss = criterion(pred, y)
print("loss after 1 step optimization: ", loss.item())

# ================================================================== #
#                     3. Loading data from numpy                     #
# ================================================================== #

# create a numpy array 
x = np.array([[1,2], [3,4]])

# convert the numpy array to a torch tensonr
y = torch.from_numpy(x)

# convert the torch tensor to a numpy array 
z = y.numpy

# ================================================================== #
#                         4. Input pipeline                          #
# ================================================================== #

# download and construct CIFAR-10 dataset
train_dataset = torchvision.datasets.CIFAR10(root="./data/",
                                             train=True,
                                             transform=transforms.ToTensor(),
                                             download=True)

# fetch one data pair
image, label = train_dataset[0]
print(image.size())
print(label)

# data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=64,
                                           shuffle=True)

# when iteration starts, queue and thread start to load data from files
data_iter =iter(train_loader)

# mini-batch images and labels
images, labels =data_iter.next()

# actual usage of the data loader is as below
for images, labels in train_loader:
    # trining code should be written here
    pass



# ================================================================== #
#                5. Input pipeline for custom dataset                #
# ================================================================== #

# you should build your custom dataset as below
class CustomDataset(torch.utils.data.Dataset):
    def __init__(self):
        # TO DO
        # 1. Initialization file paths or a list of file names
        pass

    def __getitem__(self, index):
        # TO DO
        # 1.read one data from file(e.g using numpy.fromfiel, PIL.Image.open)
        # 2.preprocess the data (e.g torchvision.Transform)
        # 3.Return a data pair (e.g image and label)
        pass

    def __len__(self):
        # you should change 0 to the total size of your dataset
        return 1

custom_dataset = CustomDataset()
train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,
                                           batch_size=64, 
                                           shuffle=True)

class CustomDataset(torch.utils.data.Dataset):
    def __init__(self):
        # TODO
        # 1. Initialize file paths or a list of file names. 
        pass
    def __getitem__(self, index):
        # TODO
        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).
        # 2. Preprocess the data (e.g. torchvision.Transform).
        # 3. Return a data pair (e.g. image and label).
        pass
    def __len__(self):
        # You should change 0 to the total size of your dataset.
        return 0 

# You can then use the prebuilt data loader. 
custom_dataset = CustomDataset()
train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,
                                           batch_size=64, 
                                           shuffle=True)

# ================================================================== #
#                        6. Pretrained model                         #
# ================================================================== #

# Download and load the pretrained ResNet-18
resnet = torchvision.models.resnet18(pretrained=True)

# set as below, to finetune only the top layer of the model
for param in resnet.parameters():
    param.requires_grad = False

# Replace the top later for finetuning
resnet.fc = nn.Linear(resnet.fc.in_features, 100)  # 100 is an example

#forward pass 
images = torch.randn(64, 3, 224, 224)
outputs = resnet(images)
print(outputs.size()) # (64, 100)

# ================================================================== #
#                      7. Save and load the model                    #
# ================================================================== #

# save and load the entire model
torch.save(resnet, 'model.ckpt')
model = torch.load('model.ckpt')

# save and load only the model parameters 
torch.save(resnet.state_dict(), 'parmas.ckpt')
resnet.load_state_dict(torch.load('params.ckpt'))

