{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASE and DATALOADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "더 나은 가독성과 모듈성을 위해 데이터셋 코드와 모델학습 코드를 분리하는것이 이상적.\n",
    "It is ideal to separate dateset codes and model training codes for the sake of better readability and modualarity\n",
    "\n",
    "Pytorch는 torch.util.data.DataLoader와 torch.utils.data.Dataset 를 제공하여 pre-loaded 데이터셋과 가지고 있는 데이터를 사용 가능 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 불러오기\n",
    "\n",
    "Fashion-MNIST 데이터셋\n",
    "- 60,000 training images\n",
    "- 10,000 test images\n",
    "\n",
    "각각의 이미지는 grayscale 28x28 이미지와 10의 label로 구성 \n",
    "\n",
    "root : 학습/테스트 데이터가 저장되는 경로 \n",
    "train : 학습용 or 테스트용 데이터셋 여부 지정 \n",
    "download=True : root에 데이터가 없는 경우 인터넷에서 다운로드 \n",
    "transform과 target_transform은 feature와 label 변형을 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "root='data',\n",
    "train=True,\n",
    "download=True,\n",
    "transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "root='data',\n",
    "train=False,\n",
    "download=True,\n",
    "transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 순회후 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\" ,\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(8,8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols*rows+1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일에서 사용자 정의 데이터 셋 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    # 함수는 dataset객체가 생성될 떄 한번 만 실행. 여기서는 annotation_file이 포함된 디렉토리와 transform을 초기화\n",
    "    def __init__(self. annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annptations_file, anmes=['file_name', 'label'])\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    # 데이터셋의 셈플 개수 반환\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    # 주어진 인덱스 idx에 해당하는 샘픙르 데이터셋에서 불러오고 반환.\n",
    "    def __getitem__(self,idx):\n",
    "        # 1. 인덱스 기반으로 디스크에서 이미지 위치 식별\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        # 2. read_image를 사용하여 이미지를 tensor롤 변환\n",
    "        image = read_image(img_path)\n",
    "        # 3. csv데이터로부터 해당하는 라벨을가져오고\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        # 4. 해당한다면, transform함수를 호출하여 텐서 이미지와 라벨을 python dict령으로 반환\n",
    "        if self.transfoem:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader로 학습용 데이터 준비하기 \n",
    "\n",
    "Dataset은 feature를 가져오고 각각의 샘플에 label값을 지정하는 작업을 동시에 수행. \n",
    "모델 학습시, 통상 minibatch로 전달하고 epoch마다 데이터를 섞어 overfitting을 방지하며, python의 multiporcessing을 사용하여 데이터 검색 속도를 높임 \n",
    "\n",
    "DataLoader는 간단한 API로 복잡한 과정들을 추상화한 iterable 객체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape:torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape:torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape:{train_features.size()}\")\n",
    "print(f\"Labels batch shape:{train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
